{
  "lesson_id": "D2-LESSON-003",
  "domain": 2,
  "title": "Social Engineering",
  "objectives_covered": ["2.2"],
  "estimated_duration": "50-60 minutes",
  "difficulty": "beginner",
  "version": "3.0-enhanced",

  "skill_tree": {
    "prerequisites": ["D2-LESSON-001", "D2-LESSON-002"],
    "unlocks": ["D2-LESSON-004", "D5-LESSON-006"],
    "cascade_learning": {
      "builds_on": [
        {"lesson": "D2-LESSON-001", "concepts": ["Different actors use social engineering differently"]},
        {"lesson": "D2-LESSON-002", "concepts": ["Social engineering exploits human attack surface"]}
      ],
      "enables": [
        {"lesson": "D2-LESSON-004", "concepts": ["Malware often delivered via social engineering"]},
        {"lesson": "D5-LESSON-006", "concepts": ["Security awareness training addresses social engineering"]}
      ]
    }
  },

  "role_relevance": {
    "soc_analyst": {
      "importance": "critical",
      "daily_tasks": [
        "Identifying social engineering attempts in reported emails",
        "Analyzing phishing campaigns targeting organization",
        "Correlating social engineering with follow-on attacks",
        "Documenting social engineering indicators"
      ],
      "real_scenario": "User reports suspicious email—you analyze headers, links, and attachments, identify phishing kit being used, and block related infrastructure"
    },
    "incident_responder": {
      "importance": "critical",
      "daily_tasks": [
        "Investigating successful social engineering attacks",
        "Determining what information attackers obtained",
        "Containing compromises from phishing",
        "Interviewing victims to understand attack methods"
      ],
      "real_scenario": "BEC incident—attacker impersonated CEO via email, finance wired $200K. You trace the email chain, identify the compromise point, and work with law enforcement"
    },
    "grc_analyst": {
      "importance": "high",
      "daily_tasks": [
        "Measuring social engineering awareness metrics",
        "Reviewing phishing simulation results",
        "Updating security awareness policies",
        "Assessing human risk factors"
      ],
      "real_scenario": "Annual security awareness review—you analyze phishing simulation click rates, identify high-risk departments, and recommend targeted training"
    },
    "penetration_tester": {
      "importance": "critical",
      "daily_tasks": [
        "Conducting social engineering engagements",
        "Crafting phishing campaigns for testing",
        "Performing vishing and pretexting",
        "Testing physical social engineering"
      ],
      "real_scenario": "Client engagement—you craft targeted phishing emails, achieve 23% click rate, and demonstrate how one click led to domain admin access"
    },
    "security_engineer": {
      "importance": "high",
      "daily_tasks": [
        "Implementing anti-phishing technologies",
        "Configuring email security controls",
        "Deploying phishing simulation platforms",
        "Building reporting mechanisms for users"
      ],
      "real_scenario": "Deploying new email security stack—you implement link protection, attachment sandboxing, and one-click phishing report button"
    }
  },

  "introduction": {
    "hook": "In 2020, a 17-year-old convinced Twitter employees he was an IT admin and gained access to internal tools. Minutes later, accounts of Obama, Biden, Elon Musk, and Apple were tweeting Bitcoin scams. No malware, no exploits, no hacking—just social engineering. The $120K Bitcoin haul was tiny compared to the stock market impact. Social engineering works because humans are the vulnerability that can't be patched.",
    "learning_goals": [
      "Identify social engineering techniques and psychological principles",
      "Recognize phishing, vishing, smishing, and other variations",
      "Understand pretexting, impersonation, and influence tactics",
      "Apply defenses against social engineering attacks"
    ],
    "why_it_matters": "Technical defenses keep improving, but humans remain exploitable. Social engineering bypasses firewalls, encryption, and access controls by targeting the human element. Understanding these techniques is essential for both defense and recognizing when you're being targeted.",
    "exam_weight": {
      "percentage": "15-18% of Domain 2",
      "question_count": "8-10 questions",
      "question_types": ["Technique identification", "Scenario classification", "Defense selection", "Psychological principle matching"]
    }
  },

  "sections": [
    {
      "section_id": "D2-L003-S01",
      "title": "Social Engineering Fundamentals",
      "content": "Social engineering manipulates people into divulging information or taking actions that compromise security.\n\n**Psychological Principles Exploited**\n\n*Authority:*\n- People comply with perceived authority figures\n- 'This is IT support, I need your password'\n- Impersonating executives, IT, law enforcement\n\n*Urgency/Scarcity:*\n- Time pressure reduces critical thinking\n- 'Your account will be closed in 24 hours'\n- Creates fear of missing out or loss\n\n*Social Proof:*\n- People follow what others do\n- 'Everyone else has already completed this'\n- Fake reviews, testimonials, popularity\n\n*Liking/Trust:*\n- People help those they like\n- Building rapport before request\n- Impersonating friends, colleagues\n\n*Reciprocity:*\n- People feel obligated to return favors\n- 'I helped you, now help me'\n- Free gifts before malicious request\n\n*Commitment/Consistency:*\n- People honor prior commitments\n- Small requests escalate to larger ones\n- 'You agreed to help earlier...'\n\n**Why Social Engineering Works**\n\n- Humans want to be helpful\n- Trust is default in professional settings\n- Busy people take shortcuts\n- Pressure overrides caution\n- Confidence inspires compliance",

      "memory_hooks": {
        "mnemonics": [
          {
            "name": "AUSLRC",
            "expansion": "Authority, Urgency, Social proof, Liking, Reciprocity, Commitment",
            "usage": "Six psychological principles attackers exploit"
          },
          {
            "name": "Hackers Hack Humans",
            "expansion": "Social engineering is hacking people, not computers",
            "usage": "Remember that people are the vulnerability being exploited"
          }
        ],
        "analogies": [
          {
            "concept": "Social Engineering = Con Artist Techniques",
            "analogy": "Social engineers are digital con artists using the same techniques: building trust, creating urgency, impersonating authority, and exploiting helpfulness. The 'Nigerian prince' scam is just digital version of centuries-old confidence tricks.",
            "why_it_works": "Con artists have exploited these principles forever—SE is the digital evolution"
          }
        ],
        "common_mistakes": [
          {
            "mistake": "Thinking only naive people fall for social engineering",
            "correction": "Security researchers, executives, and IT professionals all fall for well-crafted attacks. Sophistication of target requires sophistication of attack—but everyone is vulnerable.",
            "exam_trap": "Social engineering works on anyone—training helps but doesn't eliminate risk"
          },
          {
            "mistake": "Focusing only on phishing emails",
            "correction": "Social engineering includes vishing (phone), smishing (SMS), physical (tailgating), and in-person pretexting. All channels are attack vectors.",
            "exam_trap": "Know all SE channels—phone, SMS, in-person, not just email"
          }
        ]
      },

      "what_would_happen_if": [
        {
          "situation": "Attacker calls employee claiming to be IT during urgent 'security incident'",
          "consequence": "Authority (IT) + Urgency (incident) = compliance. Employee provides password 'to verify their account isn't compromised.' Attacker now has valid credentials.",
          "lesson": "Legitimate IT never asks for passwords. Verify identity through known channels during pressure situations."
        },
        {
          "situation": "Organization relies solely on technical controls without security awareness",
          "consequence": "Attackers bypass controls through users. User clicks link, enters credentials on fake site, opens attachment because it seems legitimate. Technical controls can't stop willing user actions.",
          "lesson": "Humans are the last line of defense. Training complements technical controls."
        }
      ],

      "glossary_terms": [
        {
          "term": "Social Engineering",
          "definition": "Psychological manipulation of people to divulge information or take security-compromising actions",
          "exam_note": "Exploits human psychology, not technical vulnerabilities"
        },
        {
          "term": "Pretexting",
          "definition": "Creating a fabricated scenario to engage victim and extract information",
          "exam_note": "The 'story' or 'cover' used in social engineering"
        },
        {
          "term": "Authority Principle",
          "definition": "Psychological tendency to comply with perceived authority figures",
          "exam_note": "Why impersonating IT/executives/police works"
        },
        {
          "term": "Urgency Principle",
          "definition": "Psychological pressure from time constraints that reduces critical thinking",
          "exam_note": "'Act now' messaging creates compliance through fear"
        }
      ],

      "knowledge_check": {
        "question": "An attacker calls an employee claiming to be from the IT help desk during a 'critical security incident' and needs their password immediately to 'protect their account.' Which TWO psychological principles are being exploited?",
        "options": [
          "Social proof and reciprocity",
          "Authority and urgency",
          "Liking and commitment",
          "Scarcity and reciprocity"
        ],
        "correct_answer": 1,
        "explanation": "The attacker claims to be IT (authority—people comply with IT staff) and creates a 'critical security incident' requiring immediate action (urgency—time pressure reduces critical thinking). These are the most commonly combined principles.",
        "wrong_answer_analysis": {
          "0": "Social proof would involve 'everyone else has done this.' Reciprocity would involve doing a favor first.",
          "2": "Liking involves building rapport. Commitment involves prior agreements. Neither is present here.",
          "3": "Scarcity involves limited availability. The scenario uses urgency (time) and authority (IT)."
        }
      },

      "must_remember": [
        "AUSLRC: Authority, Urgency, Social proof, Liking, Reciprocity, Commitment",
        "Anyone can fall for social engineering—it exploits human nature",
        "Social engineering includes all channels: email, phone, SMS, physical",
        "Legitimate IT never asks for passwords"
      ]
    },

    {
      "section_id": "D2-L003-S02",
      "title": "Phishing and Email-Based Attacks",
      "content": "Phishing uses fraudulent emails to steal credentials, deliver malware, or manipulate victims.\n\n**Phishing Types**\n\n*Phishing (Generic):*\n- Mass emails to many targets\n- Generic messaging (Netflix, Amazon, bank)\n- Low effort, high volume\n- Relies on percentage who fall for it\n\n*Spear Phishing:*\n- Targeted at specific individuals\n- Researched, personalized content\n- Higher effort, higher success rate\n- References real projects, colleagues, events\n\n*Whaling:*\n- Spear phishing targeting executives\n- High-value targets (CEO, CFO, board)\n- Often involves financial requests\n- Extremely well-researched\n\n*Business Email Compromise (BEC):*\n- Impersonates executives or vendors\n- Requests wire transfers or data\n- May use compromised accounts\n- Often no malware—just manipulation\n\n**Phishing Indicators**\n\n*Technical:*\n- Sender domain doesn't match company\n- Link destinations don't match text\n- Poor email authentication (fails SPF/DKIM)\n- Suspicious attachments\n\n*Content:*\n- Urgency and threats\n- Generic greetings ('Dear Customer')\n- Grammar and spelling errors\n- Unusual requests\n\n**Credential Harvesting**\n\n- Clone legitimate login pages\n- Capture credentials submitted\n- Often use lookalike domains\n- May proxy to real site after capture",

      "memory_hooks": {
        "mnemonics": [
          {
            "name": "PSWB",
            "expansion": "Phishing (generic), Spear phishing (targeted), Whaling (executives), BEC (impersonation)",
            "usage": "Four types of phishing from broad to targeted"
          },
          {
            "name": "Hover Before Click",
            "expansion": "Always hover over links to see real destination",
            "usage": "Simple technique to identify phishing links"
          }
        ],
        "analogies": [
          {
            "concept": "Phishing Types = Fishing Methods",
            "analogy": "Generic phishing = casting a wide net (catch whatever swims by). Spear phishing = fishing with a spear (targeting specific fish). Whaling = hunting big game (going after the biggest catches).",
            "why_it_works": "The fishing metaphor is literal—phishing was named for this reason"
          }
        ],
        "common_mistakes": [
          {
            "mistake": "Thinking grammar errors always indicate phishing",
            "correction": "Sophisticated attackers use perfect grammar. Some even intentionally target people who don't notice errors (easier marks). Don't rely on grammar alone.",
            "exam_trap": "Well-crafted phishing has no grammar errors—use multiple indicators"
          },
          {
            "mistake": "Checking only the display name, not actual email address",
            "correction": "Display names can say anything ('CEO Name <attacker@evil.com>'). Always check the actual email address, especially for sensitive requests.",
            "exam_trap": "Attackers spoof display names easily—verify actual addresses"
          }
        ]
      },

      "what_would_happen_if": [
        {
          "situation": "CFO receives email appearing from CEO requesting urgent wire transfer to new vendor",
          "consequence": "BEC attack succeeds—$500K wired to attacker's account. Email came from lookalike domain (company-inc.com vs company.com). No malware involved, just social engineering.",
          "lesson": "Wire transfer requests need out-of-band verification. Call the person using known number, not one in the email."
        },
        {
          "situation": "Employee clicks phishing link and enters credentials on fake login page",
          "consequence": "Attacker has valid credentials. If no MFA, they're in. If MFA via SMS, they may try SIM swap or real-time proxy. Credential compromise is the starting point for larger attack.",
          "lesson": "Credential harvesting is often first step. MFA helps but isn't perfect against real-time attacks."
        }
      ],

      "glossary_terms": [
        {
          "term": "Phishing",
          "definition": "Fraudulent email attempting to steal credentials or deliver malware",
          "exam_note": "Generic phishing targets mass audiences"
        },
        {
          "term": "Spear Phishing",
          "definition": "Targeted phishing attack using personalized, researched content",
          "exam_note": "Higher effort, higher success rate than generic phishing"
        },
        {
          "term": "Whaling",
          "definition": "Spear phishing specifically targeting high-level executives",
          "exam_note": "C-suite targeting—usually involves financial requests"
        },
        {
          "term": "Business Email Compromise (BEC)",
          "definition": "Attack impersonating executives or vendors to request wire transfers or sensitive data",
          "exam_note": "Often no malware—pure social engineering"
        }
      ],

      "knowledge_check": {
        "question": "An attacker sends a carefully researched email to the VP of Finance that references a real ongoing acquisition and requests tax documents for due diligence. The email appears to come from the company's legal counsel. What type of attack is this?",
        "options": [
          "Generic phishing campaign",
          "Spear phishing with extensive reconnaissance",
          "Whaling targeting executive",
          "Both B and C—spear phishing that qualifies as whaling"
        ],
        "correct_answer": 3,
        "explanation": "This is both spear phishing (targeted, researched, personalized) AND whaling (targeting an executive - VP of Finance). Whaling is a subset of spear phishing that specifically targets high-level executives.",
        "wrong_answer_analysis": {
          "0": "Generic phishing uses mass emails without personalization—this is highly targeted.",
          "1": "While technically spear phishing, the executive targeting makes it whaling too.",
          "2": "While technically whaling, it's done through spear phishing techniques."
        }
      },

      "must_remember": [
        "Phishing → Spear Phishing → Whaling (increasing targeting)",
        "BEC impersonates executives/vendors for wire transfers",
        "Hover over links to see real destination",
        "Verify wire transfer requests out-of-band (phone call to known number)"
      ]
    },

    {
      "section_id": "D2-L003-S03",
      "title": "Voice, SMS, and Physical Social Engineering",
      "content": "Social engineering extends beyond email to all communication channels and physical access.\n\n**Vishing (Voice Phishing)**\n\n*Techniques:*\n- Impersonating IT support, banks, government\n- Caller ID spoofing to appear legitimate\n- Pretexting with fabricated scenarios\n- Pressure tactics (urgency, authority)\n\n*Common Scenarios:*\n- 'Microsoft support' detecting problems\n- Bank fraud department verification\n- IRS/government payment demands\n- IT help desk password requests\n\n**Smishing (SMS Phishing)**\n\n*Techniques:*\n- Malicious links in text messages\n- Fake package delivery notifications\n- Bank alerts requiring 'verification'\n- Prize/lottery winner claims\n\n*Why Effective:*\n- Harder to inspect links on mobile\n- SMS feels more personal/trustworthy\n- Immediate notification creates urgency\n\n**Physical Social Engineering**\n\n*Tailgating/Piggybacking:*\n- Following authorized person through secure door\n- Exploits politeness (holding doors open)\n- Defense: Mantraps, security awareness\n\n*Impersonation:*\n- Pretending to be delivery person, contractor, IT\n- Uniform or badge creates legitimacy\n- Defense: Verify with known contacts, escort visitors\n\n*Dumpster Diving:*\n- Searching trash for sensitive information\n- Org charts, passwords, financial data\n- Defense: Shredding, secure disposal\n\n*Shoulder Surfing:*\n- Observing screens, keyboards, PIN pads\n- Public places especially vulnerable\n- Defense: Privacy screens, awareness",

      "memory_hooks": {
        "mnemonics": [
          {
            "name": "VSP = Non-Email SE",
            "expansion": "Vishing (voice), Smishing (SMS), Physical",
            "usage": "Three social engineering channels beyond email"
          },
          {
            "name": "TIDS = Physical SE",
            "expansion": "Tailgating, Impersonation, Dumpster diving, Shoulder surfing",
            "usage": "Four physical social engineering techniques"
          }
        ],
        "analogies": [
          {
            "concept": "Tailgating = Sneaking Into a Concert",
            "analogy": "Wait for someone with a ticket to open the gate, then follow through before it closes. Same principle—exploiting someone else's authorized access to bypass controls.",
            "why_it_works": "Concert sneaking is familiar unauthorized access through tailgating"
          }
        ],
        "common_mistakes": [
          {
            "mistake": "Trusting caller ID displays",
            "correction": "Caller ID is trivially spoofed. An incoming call showing 'Company IT Support' means nothing. Verify by calling back using known numbers.",
            "exam_trap": "Caller ID spoofing is common in vishing—never trust displayed numbers"
          },
          {
            "mistake": "Being polite over being secure (holding doors)",
            "correction": "Security culture should override politeness norms. Everyone should badge in individually. 'Sorry, security policy' is acceptable.",
            "exam_trap": "Tailgating exploits social politeness—organizations must create security culture"
          }
        ]
      },

      "what_would_happen_if": [
        {
          "situation": "Employee receives call from 'Microsoft Support' about computer problems, grants remote access",
          "consequence": "Scammer installs malware, steals data, encrypts files for ransom. Common tech support scam targeting non-technical users. Microsoft never calls unsolicited.",
          "lesson": "Legitimate companies don't call about problems. Hang up and call official numbers if concerned."
        },
        {
          "situation": "Person in delivery uniform follows employee through secure door",
          "consequence": "Attacker now inside secure area. Can plant devices, access systems, steal equipment. Uniform creates assumption of legitimacy that isn't verified.",
          "lesson": "Verify all visitors. Escort unknowns. Don't hold doors—everyone badges individually."
        }
      ],

      "glossary_terms": [
        {
          "term": "Vishing",
          "definition": "Voice phishing—social engineering attacks conducted over phone calls",
          "exam_note": "Often involves caller ID spoofing and impersonation"
        },
        {
          "term": "Smishing",
          "definition": "SMS phishing—social engineering attacks via text messages",
          "exam_note": "Exploits difficulty inspecting links on mobile devices"
        },
        {
          "term": "Tailgating",
          "definition": "Following an authorized person through a secure entry point",
          "exam_note": "Also called piggybacking—exploits social politeness"
        },
        {
          "term": "Shoulder Surfing",
          "definition": "Observing someone's screen, keyboard, or PIN entry to steal information",
          "exam_note": "Common in public places—defense is privacy screens"
        }
      ],

      "knowledge_check": {
        "question": "An employee receives a text message stating 'Your package delivery failed. Click here to reschedule: [link]' when they haven't ordered anything. What type of attack is this?",
        "options": [
          "Vishing attempting to steal credentials",
          "Smishing using fake delivery notification",
          "Spear phishing targeting the employee",
          "Business email compromise"
        ],
        "correct_answer": 1,
        "explanation": "This is smishing (SMS phishing)—a text message with a malicious link using a fake delivery notification pretext. The link likely leads to credential harvesting or malware download. This is a common smishing scenario.",
        "wrong_answer_analysis": {
          "0": "Vishing is voice/phone-based, not SMS.",
          "2": "Spear phishing would be email-based and targeted. This is generic SMS.",
          "3": "BEC involves impersonating executives via email for wire transfers."
        }
      },

      "must_remember": [
        "Vishing = voice, Smishing = SMS, both use same principles as email phishing",
        "Caller ID is easily spoofed—never trust displayed numbers",
        "TIDS physical SE: Tailgating, Impersonation, Dumpster diving, Shoulder surfing",
        "Everyone badges individually—don't hold doors for strangers"
      ]
    },

    {
      "section_id": "D2-L003-S04",
      "title": "Social Engineering Defenses",
      "content": "Defending against social engineering requires combining technical controls with human awareness.\n\n**Security Awareness Training**\n\n*Effective Programs:*\n- Regular, ongoing training (not just annual)\n- Interactive and engaging content\n- Role-specific scenarios\n- Immediate feedback on mistakes\n\n*Key Topics:*\n- Recognizing phishing indicators\n- Reporting suspicious activity\n- Verification procedures\n- Physical security awareness\n\n**Phishing Simulations**\n\n*Purpose:*\n- Measure organizational vulnerability\n- Provide teachable moments\n- Track improvement over time\n- Identify high-risk groups\n\n*Best Practices:*\n- Progressively difficult scenarios\n- Immediate training on failure\n- Non-punitive culture\n- Executive participation\n\n**Technical Controls**\n\n*Email:*\n- Anti-phishing gateways\n- Link protection/rewriting\n- Attachment sandboxing\n- External email warnings\n- Report phishing buttons\n\n*Phone/SMS:*\n- Call authentication (STIR/SHAKEN)\n- SMS filtering\n- Verified number directories\n\n**Procedural Controls**\n\n*Verification Protocols:*\n- Out-of-band verification for sensitive requests\n- Callback procedures using known numbers\n- Multi-person approval for wire transfers\n- Change verification for vendor payments\n\n**Culture of Security**\n\n- Empower questioning of unusual requests\n- No punishment for verification delays\n- Recognition for reporting\n- Leadership modeling behavior",

      "memory_hooks": {
        "mnemonics": [
          {
            "name": "STOP-THINK-VERIFY",
            "expansion": "Stop (don't react immediately), Think (is this unusual?), Verify (confirm through known channels)",
            "usage": "User response to suspicious requests"
          },
          {
            "name": "TCP = SE Defense Layers",
            "expansion": "Training, Controls (technical), Procedures",
            "usage": "Three layers of social engineering defense"
          }
        ],
        "analogies": [
          {
            "concept": "Security Culture = Neighborhood Watch",
            "analogy": "In a good neighborhood watch, everyone looks out for suspicious activity and reports it without embarrassment. Security culture works the same—everyone watches for threats and feels empowered to report.",
            "why_it_works": "Neighborhood watch is familiar collective security model"
          }
        ],
        "common_mistakes": [
          {
            "mistake": "Punishing users who fall for simulations",
            "correction": "Punishment creates fear and reduced reporting. Focus on education and improvement. Celebrate reporting, even of successful attacks.",
            "exam_trap": "Phishing programs should be non-punitive to encourage reporting"
          },
          {
            "mistake": "Annual training only",
            "correction": "Annual training creates brief awareness spike that fades. Continuous training, regular simulations, and ongoing reinforcement maintain awareness.",
            "exam_trap": "Effective awareness training is ongoing, not just annual compliance"
          }
        ]
      },

      "what_would_happen_if": [
        {
          "situation": "Organization implements phishing simulation but punishes failures with public shaming",
          "consequence": "Users stop reporting phishing (fear of punishment). When real attacks succeed, nobody reports them. Shame culture reduces, not improves, security.",
          "lesson": "Non-punitive culture encourages reporting. Celebrate catches, educate on misses."
        },
        {
          "situation": "Company requires out-of-band verification for all wire transfers over $10K",
          "consequence": "BEC attack fails—attacker's email requests wire transfer but finance calls CEO at known number to verify. CEO says 'I didn't request that.' Attack stopped.",
          "lesson": "Procedural controls (verification requirements) stop social engineering that bypasses technical controls."
        }
      ],

      "glossary_terms": [
        {
          "term": "Security Awareness Training",
          "definition": "Educational program teaching employees to recognize and respond to security threats",
          "exam_note": "Should be ongoing and engaging, not just annual compliance"
        },
        {
          "term": "Phishing Simulation",
          "definition": "Controlled phishing exercises to test and train employee awareness",
          "exam_note": "Provides metrics and teachable moments—should be non-punitive"
        },
        {
          "term": "Out-of-Band Verification",
          "definition": "Confirming requests through different communication channel than original request",
          "exam_note": "Email request → phone verification using known number"
        },
        {
          "term": "STIR/SHAKEN",
          "definition": "Framework for authenticating caller ID to prevent spoofing",
          "exam_note": "Technical control for vishing defense"
        }
      ],

      "knowledge_check": {
        "question": "A finance employee receives an email from 'CEO' requesting an urgent wire transfer. Following company policy, they call the CEO at a number they have on file to verify. The CEO confirms they did NOT send the request. What control prevented this attack?",
        "options": [
          "Email filtering that should have blocked the message",
          "Phishing simulation training the employee received",
          "Out-of-band verification procedure for wire transfers",
          "Technical control identifying spoofed sender"
        ],
        "correct_answer": 2,
        "explanation": "The procedural control—requiring out-of-band verification (phone call to known number) for wire transfers—stopped this BEC attack. The employee followed proper procedure and caught the fraud before money was lost.",
        "wrong_answer_analysis": {
          "0": "The email got through filtering—it wasn't blocked.",
          "1": "Training helped recognize the need to verify, but the procedure itself stopped the attack.",
          "3": "Technical controls didn't stop it—the email arrived. Procedure saved the day."
        }
      },

      "must_remember": [
        "TCP defense: Training + Controls (technical) + Procedures",
        "STOP-THINK-VERIFY for suspicious requests",
        "Out-of-band verification stops BEC attacks",
        "Non-punitive culture encourages reporting"
      ]
    }
  ],

  "summary": {
    "key_takeaways": [
      "AUSLRC principles: Authority, Urgency, Social proof, Liking, Reciprocity, Commitment",
      "Phishing types: Generic → Spear Phishing → Whaling → BEC",
      "Non-email SE: Vishing (voice), Smishing (SMS), Physical (TIDS)",
      "Defense layers: Training + Technical Controls + Procedures",
      "Out-of-band verification stops BEC and wire fraud"
    ],
    "exam_focus": "SE technique identification, psychological principles, phishing types, defense strategies",
    "next_lesson": "D2-LESSON-004: Malware Types—the payloads delivered through social engineering"
  }
}
