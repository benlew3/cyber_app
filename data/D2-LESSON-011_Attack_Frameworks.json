{
  "lesson_id": "D2-LESSON-011",
  "domain": 2,
  "title": "Attack Frameworks and Methodologies",
  "objectives_covered": ["2.1", "2.4"],
  "estimated_duration": "45-50 minutes",
  "difficulty": "intermediate",
  "prerequisites": ["D2-LESSON-001", "D2-LESSON-008"],

  "introduction": {
    "hook": "When security researchers analyzed the SolarWinds attack, they didn't just list indicators of compromiseâ€”they mapped the entire attack to the MITRE ATT&CK framework, revealing 18 distinct techniques across 9 tactics. This systematic analysis helped thousands of organizations understand exactly where to look for compromise and what defenses might have stopped the attack. Attack frameworks transform chaotic incident data into structured intelligence, enabling defenders to think like attackers and disrupt attacks at any stage.",
    "learning_goals": [
      "Apply the Cyber Kill Chain to understand attack progression and identify defensive opportunities",
      "Navigate the MITRE ATT&CK framework to analyze techniques and map defenses",
      "Use the Diamond Model to analyze intrusions and attribute attacks",
      "Understand penetration testing methodologies and their structured approaches",
      "Apply frameworks to improve threat detection and defensive strategies"
    ],
    "why_it_matters": "Attackers follow patterns. Understanding these patterns through structured frameworks helps defenders anticipate threats, detect intrusions earlier, and build comprehensive defenses. Security professionals use these frameworks dailyâ€”to analyze incidents, develop detection rules, assess security coverage, and communicate about threats. The Security+ exam tests framework knowledge directly. Expect 4-6 questions on the Cyber Kill Chain, MITRE ATT&CK, and attack methodologies."
  },

  "sections": [
    {
      "section_id": "D2-L011-S01",
      "title": "The Cyber Kill Chain",
      "content": "The Cyber Kill Chain, developed by Lockheed Martin, describes the stages of a targeted attack and provides a framework for understanding and disrupting attacks.\n\n**Kill Chain Overview**\n\n*Concept*\n- Military concept adapted for cyber\n- Attacks progress through stages\n- Breaking any link disrupts the attack\n- Defenders have multiple opportunities\n- Left of boom vs. right of boom\n\n**The Seven Stages**\n\n*1. Reconnaissance*\n- Attacker gathers information\n- OSINT, social media, scanning\n- Identify targets, technologies, people\n- Often months before attack\n\n*Defense*: Limit public information, monitor for reconnaissance\n\n*2. Weaponization*\n- Create attack payload\n- Combine exploit with malware\n- Develop delivery mechanism\n- Test against defenses\n\n*Defense*: Understand attacker capabilities, threat intelligence\n\n*3. Delivery*\n- Transmit weapon to target\n- Phishing emails, malicious websites\n- USB drives, supply chain\n- Watering hole attacks\n\n*Defense*: Email filtering, web filtering, user awareness\n\n*4. Exploitation*\n- Trigger the vulnerability\n- Execute attacker's code\n- Gain initial access\n- Browser, document, or service exploit\n\n*Defense*: Patching, endpoint protection, exploit mitigation\n\n*5. Installation*\n- Establish persistence\n- Install backdoor or malware\n- Create accounts, scheduled tasks\n- Modify system\n\n*Defense*: Application whitelisting, HIDS, baseline monitoring\n\n*6. Command and Control (C2)*\n- Establish communication channel\n- Receive commands\n- Exfiltrate data\n- Blend into normal traffic\n\n*Defense*: Network monitoring, egress filtering, DNS analysis\n\n*7. Actions on Objectives*\n- Achieve attacker's goals\n- Data exfiltration\n- System destruction\n- Lateral movement\n- Mission accomplished\n\n*Defense*: DLP, network segmentation, insider threat detection\n\n**Using the Kill Chain Defensively**\n\n*Intelligence-Driven Defense*\n- Map indicators to kill chain stages\n- Identify gaps in detection\n- Measure defense coverage\n- Prioritize investments\n\n*Breaking the Chain*\n- Stop attack at any stage\n- Earlier is better (left of boom)\n- Multiple detection opportunities\n- Defense in depth",

      "key_points": [
        "7 stages: Recon â†’ Weaponization â†’ Delivery â†’ Exploitation â†’ Installation â†’ C2 â†’ Actions",
        "Breaking any link disrupts the attackâ€”multiple defensive opportunities",
        "Earlier detection (left of boom) prevents more damage",
        "Each stage has specific defensive controls",
        "Map indicators and defenses to kill chain stages for gap analysis"
      ],

      "real_world_example": {
        "scenario": "Mapping attack to Cyber Kill Chain",
        "company": "Analysis of SolarWinds Attack",
        "application": "The SolarWinds attack mapped to kill chain stages: RECONNAISSANCE (attackers researched SolarWinds development process, identified Orion as target), WEAPONIZATION (developed SUNBURST malware designed to hide in Orion updates), DELIVERY (compromised SolarWinds build process, malicious code included in legitimate updates), EXPLOITATION (customers installed 'legitimate' updates containing backdoor), INSTALLATION (SUNBURST established persistence, deployed additional malware like TEARDROP), C2 (DNS-based communication mimicking legitimate SolarWinds traffic, very stealthy), ACTIONS (18,000+ orgs received malware, attackers selectively exploited high-value targets including government agencies). The attack succeeded largely because early stages (weaponization, delivery) were undetected."
      },

      "exam_tips": [
        "Know all 7 stages in order: Recon, Weapon, Deliver, Exploit, Install, C2, Actions",
        "Reconnaissance is information gathering BEFORE the attack",
        "Delivery is how the weapon reaches the target (email, web, USB)",
        "C2 = Command and Control = attacker communication channel",
        "Breaking any stage disrupts the attack"
      ],

      "glossary_terms": [
        {
          "term": "Cyber Kill Chain",
          "definition": "A framework developed by Lockheed Martin that describes the stages of a targeted cyber attack, from reconnaissance through actions on objectives.",
          "exam_note": "7 stages. Break any stage to disrupt attack. Earlier detection = less damage."
        },
        {
          "term": "Command and Control (C2)",
          "definition": "The communication channel established by attackers to control compromised systems, receive commands, and exfiltrate data.",
          "exam_note": "Attacker communication. Stage 6 of kill chain. Detect via network monitoring."
        },
        {
          "term": "Actions on Objectives",
          "definition": "The final stage of the kill chain where attackers achieve their goals, such as data theft, system destruction, or persistent access.",
          "exam_note": "Stage 7. Attacker achieves goal. Last chance to detect. DLP, segmentation help."
        },
        {
          "term": "Left of Boom",
          "definition": "Actions taken before an attack succeeds, representing proactive and preventive security measures.",
          "exam_note": "Before compromise. Prevention focus. Earlier in kill chain. More effective."
        }
      ],

      "knowledge_check": {
        "question": "An attacker sends a phishing email with a malicious PDF attachment to employees. This activity occurs at which stage of the Cyber Kill Chain?",
        "options": [
          "Reconnaissance because the attacker is targeting employees",
          "Weaponization because the PDF contains malware",
          "Delivery because the weapon is being transmitted to targets",
          "Exploitation because the attack is underway"
        ],
        "correct": 2,
        "explanation": "This is the Delivery stageâ€”the attacker is transmitting the weaponized payload (malicious PDF) to the target (employees via email). Reconnaissance would be gathering information about targets. Weaponization was creating the malicious PDF. Exploitation occurs when the user opens the PDF and the malware executes."
      }
    },
    {
      "section_id": "D2-L011-S02",
      "title": "MITRE ATT&CK Framework",
      "content": "MITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) is a comprehensive knowledge base of adversary behavior, providing a common language for threat intelligence and defensive analysis.\n\n**ATT&CK Overview**\n\n*Structure*\n- Tactics: What attackers want to achieve (goals)\n- Techniques: How they achieve it (methods)\n- Sub-techniques: More specific variations\n- Procedures: Specific implementations by threat actors\n\n*Matrices*\n- Enterprise ATT&CK (Windows, macOS, Linux, Cloud)\n- Mobile ATT&CK (iOS, Android)\n- ICS ATT&CK (Industrial Control Systems)\n\n**Enterprise ATT&CK Tactics (14 Tactics)**\n\n*1. Reconnaissance*\n- Gathering information about target\n- Active and passive techniques\n\n*2. Resource Development*\n- Acquiring infrastructure, tools\n- Developing capabilities\n\n*3. Initial Access*\n- Gaining first foothold\n- Phishing, valid accounts, exploits\n\n*4. Execution*\n- Running malicious code\n- PowerShell, scripts, user execution\n\n*5. Persistence*\n- Maintaining access across restarts\n- Registry, scheduled tasks, accounts\n\n*6. Privilege Escalation*\n- Gaining higher permissions\n- Exploits, credential access\n\n*7. Defense Evasion*\n- Avoiding detection\n- Obfuscation, disabling security tools\n\n*8. Credential Access*\n- Stealing credentials\n- Dumping, keylogging, brute force\n\n*9. Discovery*\n- Learning about environment\n- Network, system, account discovery\n\n*10. Lateral Movement*\n- Moving through network\n- Remote services, pass-the-hash\n\n*11. Collection*\n- Gathering target data\n- Screen capture, email collection\n\n*12. Command and Control*\n- Communicating with compromised systems\n- Encrypted channels, proxies\n\n*13. Exfiltration*\n- Stealing data\n- Over C2, web services, physical\n\n*14. Impact*\n- Disruption, destruction\n- Ransomware, data destruction\n\n**Using ATT&CK**\n\n*Detection Development*\n- Map detection rules to techniques\n- Identify coverage gaps\n- Prioritize based on threat actors\n\n*Threat Intelligence*\n- Describe adversary behavior\n- Common language across organizations\n- Track threat actor TTPs\n\n*Red/Blue Teaming*\n- Red team uses ATT&CK to plan attacks\n- Blue team uses ATT&CK to improve defenses\n- Purple team collaborates using shared framework",

      "key_points": [
        "ATT&CK structure: Tactics (goals) â†’ Techniques (methods) â†’ Sub-techniques â†’ Procedures",
        "14 Enterprise tactics from Reconnaissance to Impact",
        "Matrices for Enterprise, Mobile, and ICS environments",
        "Used for detection development, threat intel, and red/blue teaming",
        "Provides common language for describing adversary behavior"
      ],

      "real_world_example": {
        "scenario": "Using ATT&CK for detection gap analysis",
        "company": "Pinnacle Financial Services",
        "application": "Pinnacle used ATT&CK to assess their detection capabilities: THREAT ACTOR ANALYSIS (identified APT groups targeting financial sector, mapped their known techniques), DETECTION INVENTORY (mapped all SIEM rules and EDR detections to ATT&CK techniques), GAP ANALYSIS (found 40% of techniques used by relevant threat actors had no detection), PRIORITIZATION (prioritized gaps by threat actor relevance: T1059 Command & Scripting Interpreter, T1053 Scheduled Task/Job, T1003 OS Credential Dumping), DEVELOPMENT (created new detection rules for priority gaps), VALIDATION (purple team exercises validated new detections). Coverage improved from 60% to 85% for relevant techniques."
      },

      "exam_tips": [
        "Tactics = WHAT (goals); Techniques = HOW (methods)",
        "14 Enterprise tactics: Recon through Impact",
        "Know key tactics: Initial Access, Persistence, Lateral Movement, Exfiltration",
        "ATT&CK provides common language for threat intelligence",
        "Used for detection development and gap analysis"
      ],

      "glossary_terms": [
        {
          "term": "MITRE ATT&CK",
          "definition": "A globally-accessible knowledge base of adversary tactics and techniques based on real-world observations, used for threat modeling and defensive improvements.",
          "exam_note": "Tactics (what) + Techniques (how). 14 Enterprise tactics. Common language. Free."
        },
        {
          "term": "Tactic (ATT&CK)",
          "definition": "The tactical goal an adversary is trying to achieve, representing the 'why' of an ATT&CK technique.",
          "exam_note": "Adversary goal. Why they're doing something. 14 in Enterprise ATT&CK."
        },
        {
          "term": "Technique (ATT&CK)",
          "definition": "The specific method an adversary uses to achieve a tactical goal, representing the 'how' of an attack.",
          "exam_note": "How adversary achieves goal. Multiple techniques per tactic. Has sub-techniques."
        },
        {
          "term": "TTP",
          "definition": "Tactics, Techniques, and Proceduresâ€”the patterns of behavior associated with a specific threat actor or attack.",
          "exam_note": "Behavior patterns. More reliable than IOCs. Characterizes threat actors."
        }
      ],

      "knowledge_check": {
        "question": "A security team is mapping their detection rules to understand what adversary behaviors they can detect. They discover they have no detection for 'OS Credential Dumping' or 'Scheduled Task' techniques. This analysis is using which framework?",
        "options": [
          "Cyber Kill Chain because it shows attack progression",
          "MITRE ATT&CK because it maps specific adversary techniques",
          "Diamond Model because it analyzes adversary relationships",
          "STRIDE because it categorizes threats"
        ],
        "correct": 1,
        "explanation": "This is MITRE ATT&CKâ€”mapping detection rules to specific adversary techniques (like T1003 OS Credential Dumping and T1053 Scheduled Task) to identify detection gaps. The Cyber Kill Chain shows stages but not specific techniques. The Diamond Model analyzes intrusion relationships. STRIDE is for threat modeling applications."
      }
    },
    {
      "section_id": "D2-L011-S03",
      "title": "Diamond Model of Intrusion Analysis",
      "content": "The Diamond Model provides a framework for analyzing intrusions by examining the relationships between adversaries, capabilities, infrastructure, and victims.\n\n**Diamond Model Core Features**\n\n*Four Vertices*\n\n*1. Adversary*\n- The threat actor\n- Nation-state, criminal, hacktivist\n- Operator (who) vs. Customer (why)\n- Attribution target\n\n*2. Capability*\n- Tools and techniques used\n- Malware, exploits, TTPs\n- Adversary's ability\n- Can be shared across actors\n\n*3. Infrastructure*\n- Physical and logical resources\n- C2 servers, domains, email\n- Attacker-controlled assets\n- Often reused\n\n*4. Victim*\n- Target of the attack\n- Organization, person, system\n- Target (intended) vs. Target (actual)\n- Assets affected\n\n**Relationships and Axes**\n\n*Socio-Political Axis*\n- Adversary â†” Victim relationship\n- Why this victim?\n- Motivation, targeting logic\n\n*Technical Axis*\n- Capability â†” Infrastructure relationship\n- How attack was delivered\n- Technical execution\n\n**Meta-Features**\n\n*Timestamp*\n- When events occurred\n- Attack timeline\n\n*Phase*\n- Kill chain stage\n- ATT&CK tactic\n\n*Result*\n- Success or failure\n- Impact achieved\n\n*Direction*\n- Adversary-to-victim\n- Victim-to-infrastructure\n- Bidirectional\n\n*Methodology*\n- Attack type\n- Phishing, watering hole, etc.\n\n*Resources*\n- What was required\n- Cost, time, expertise\n\n**Using the Diamond Model**\n\n*Activity Threading*\n- Connect related events\n- Same adversary, different attacks\n- Track campaigns over time\n\n*Activity-Attack Graphs*\n- Visualize attack progression\n- Multiple diamonds per attack\n- Show relationships\n\n*Pivoting Analysis*\n- Start with one vertex\n- Discover related elements\n- Expand investigation\n\n*Attribution*\n- Build evidence for actor identification\n- Connect multiple incidents\n- Cluster similar attacks",

      "key_points": [
        "Four vertices: Adversary, Capability, Infrastructure, Victim",
        "Socio-political axis (why): Adversary â†” Victim relationship",
        "Technical axis (how): Capability â†” Infrastructure relationship",
        "Used for intrusion analysis, attribution, and connecting related attacks",
        "Pivoting from known elements discovers related unknown elements"
      ],

      "real_world_example": {
        "scenario": "Diamond Model analysis of APT campaign",
        "company": "Financial Sector Attribution",
        "application": "Analysts used the Diamond Model to analyze attacks on multiple banks: ADVERSARY (unknown initially, likely financially motivated), CAPABILITY (custom malware 'FastCash', SWIFT manipulation tools), INFRASTRUCTURE (C2 servers in Eastern Europe, compromised banking sites for watering hole), VICTIM (banks in Asia and Africa), PIVOTING (from infrastructure, found same C2 used against other banks; from capability, found FastCash linked to known APT), ATTRIBUTION (combined analysis linked to Lazarus Group/North Korea), CAMPAIGN MAPPING (connected 35 incidents over 3 years). Diamond Model enabled connecting disparate incidents to single threat actor."
      },

      "exam_tips": [
        "Four vertices: Adversary, Capability, Infrastructure, Victim",
        "Socio-political axis = Adversary-Victim (the 'why')",
        "Technical axis = Capability-Infrastructure (the 'how')",
        "Used for attribution and connecting related attacks",
        "Pivoting = using known vertex to discover unknown related elements"
      ],

      "glossary_terms": [
        {
          "term": "Diamond Model",
          "definition": "An intrusion analysis framework that examines attacks through four core features: Adversary, Capability, Infrastructure, and Victim.",
          "exam_note": "4 vertices. Socio-political and technical axes. Used for attribution and analysis."
        },
        {
          "term": "Activity Threading",
          "definition": "Using the Diamond Model to connect related security events and track adversary campaigns over time.",
          "exam_note": "Connect related attacks. Track campaigns. Same adversary, multiple incidents."
        },
        {
          "term": "Pivoting (Analysis)",
          "definition": "Starting from a known element (like infrastructure) to discover related unknown elements (like other victims or capabilities).",
          "exam_note": "Start with known. Discover related unknowns. Expand investigation scope."
        }
      ],

      "knowledge_check": {
        "question": "Analysts investigating an attack identify a C2 server domain. They search threat intelligence and find the same domain was used in attacks against three other organizations. Using known infrastructure to discover related victims is an example of:",
        "options": [
          "Kill chain analysis mapping attack stages",
          "ATT&CK technique identification",
          "Diamond Model pivoting from infrastructure to victims",
          "STRIDE threat modeling"
        ],
        "correct": 2,
        "explanation": "This is Diamond Model pivotingâ€”using a known vertex (infrastructure/C2 domain) to discover related unknown vertices (other victims). The Diamond Model specifically enables this type of analysis by examining relationships between adversaries, capabilities, infrastructure, and victims. Kill chain maps stages. ATT&CK identifies techniques. STRIDE is for application threat modeling."
      }
    },
    {
      "section_id": "D2-L011-S04",
      "title": "Penetration Testing Methodologies",
      "content": "Penetration testing follows structured methodologies to ensure comprehensive coverage, repeatable results, and professional execution.\n\n**Common Methodologies**\n\n*PTES (Penetration Testing Execution Standard)*\n\n1. Pre-engagement Interactions\n   - Scoping and agreements\n   - Rules of engagement\n   - Legal considerations\n\n2. Intelligence Gathering\n   - OSINT reconnaissance\n   - Target enumeration\n   - Footprinting\n\n3. Threat Modeling\n   - Identify valuable assets\n   - Potential attack vectors\n   - Prioritize targets\n\n4. Vulnerability Analysis\n   - Scanning and enumeration\n   - Manual testing\n   - Vulnerability validation\n\n5. Exploitation\n   - Attempt to compromise\n   - Gain access\n   - Bypass security controls\n\n6. Post-Exploitation\n   - Maintain access\n   - Pivot/lateral movement\n   - Data exfiltration (if scoped)\n\n7. Reporting\n   - Document findings\n   - Risk ratings\n   - Remediation recommendations\n\n*OWASP Testing Guide*\n- Web application focused\n- Comprehensive test cases\n- Aligned with OWASP Top 10\n- Updated regularly\n\n*OSSTMM (Open Source Security Testing Methodology Manual)*\n- Operational security testing\n- Metrics-based approach\n- Comprehensive coverage\n- Scientific methodology\n\n**Testing Types**\n\n*External Testing*\n- Attack from internet\n- Perimeter assessment\n- Public-facing systems\n- External attacker simulation\n\n*Internal Testing*\n- Attack from inside network\n- Insider threat simulation\n- Assume breach scenario\n- Lateral movement focus\n\n*Blind/Double-Blind Testing*\n- Limited information provided\n- Simulates real attack\n- Tests detection capabilities\n- Double-blind: defenders unaware\n\n*Targeted Testing*\n- Full knowledge sharing\n- Collaborative approach\n- Focus on specific systems\n- Educational for both teams\n\n**Red Team vs. Penetration Testing**\n\n*Penetration Testing*\n- Find vulnerabilities\n- Defined scope and timeframe\n- Tests controls\n- Comprehensive coverage\n\n*Red Teaming*\n- Simulate real adversary\n- Objective-based (get to X)\n- Tests detection and response\n- Longer timeframe\n- Uses TTPs of real threat actors",

      "key_points": [
        "PTES: 7 phases from pre-engagement through reporting",
        "OWASP Testing Guide focuses on web applications",
        "External tests perimeter; Internal assumes network access",
        "Double-blind: testers have no info AND defenders don't know test is happening",
        "Red team simulates adversary (objectives); Pen test finds vulnerabilities (coverage)"
      ],

      "real_world_example": {
        "scenario": "Structured penetration test using PTES",
        "company": "MedCare Health Systems",
        "application": "MedCare engaged a penetration testing firm following PTES: PRE-ENGAGEMENT (defined scope: external perimeter, signed authorization, emergency contacts), INTELLIGENCE GATHERING (OSINT found employee emails, technology stack, public systems), THREAT MODELING (prioritized patient portal as high-value target), VULNERABILITY ANALYSIS (scanning found outdated web server, SQL injection in search), EXPLOITATION (SQLi exploited to access patient database in test environmentâ€”stopped per RoE), POST-EXPLOITATION (demonstrated what access SQLi would provide, lateral movement paths), REPORTING (executive summary, technical details, CVSS scores, remediation priority). Structured approach ensured comprehensive coverage and professional deliverable."
      },

      "exam_tips": [
        "PTES = 7 phase penetration testing methodology",
        "OWASP = web application testing guide",
        "External = outside perimeter; Internal = inside network",
        "Double-blind = testers AND defenders uninformed (tests detection)",
        "Red team = adversary simulation, objective-based; Pen test = vulnerability focused"
      ],

      "glossary_terms": [
        {
          "term": "PTES",
          "definition": "Penetration Testing Execution Standardâ€”a comprehensive methodology defining how penetration tests should be conducted through seven phases.",
          "exam_note": "7 phases. Pre-engagement through reporting. Industry standard methodology."
        },
        {
          "term": "Rules of Engagement",
          "definition": "Documented guidelines that define the scope, limitations, and authorization for a penetration test.",
          "exam_note": "What's allowed. What's off-limits. Legal protection. Part of pre-engagement."
        },
        {
          "term": "Double-Blind Testing",
          "definition": "A penetration test where testers have no prior information AND the target's security team is unaware the test is occurring.",
          "exam_note": "Tests real detection/response. Most realistic. Testers AND defenders uninformed."
        },
        {
          "term": "Red Team",
          "definition": "A group that simulates real adversaries using their tactics and techniques to test an organization's detection and response capabilities.",
          "exam_note": "Simulates adversary. Objective-based. Tests detection. Longer than pen test."
        }
      ],

      "knowledge_check": {
        "question": "A security assessment is planned where the testing team will have no information about the target network, and the organization's security team will not be told a test is occurring. This is designed to test realistic detection capabilities. This is called:",
        "options": [
          "Black box testing because testers have no knowledge",
          "Double-blind testing because both testers and defenders are uninformed",
          "Red team engagement because it simulates an adversary",
          "External penetration test because it's from outside"
        ],
        "correct": 1,
        "explanation": "This is double-blind testingâ€”both the testers have no prior information (blind) AND the defenders don't know a test is happening (double-blind). This provides the most realistic test of detection and response capabilities. Black box just means testers have no information. Red team is adversary simulation but defenders may know. External refers to network position, not information sharing."
      }
    },
    {
      "section_id": "D2-L011-S05",
      "title": "Applying Frameworks for Defense",
      "content": "Effective defense uses attack frameworks to think like an attacker, build detection coverage, and continuously improve security posture.\n\n**Framework Integration**\n\n*Combining Frameworks*\n- Kill Chain: Understand attack flow\n- ATT&CK: Map specific techniques\n- Diamond Model: Analyze and attribute\n- Use together for comprehensive view\n\n*Kill Chain + ATT&CK Mapping*\n- Kill chain stages â†’ ATT&CK tactics\n- Reconnaissance â†’ Reconnaissance\n- Delivery â†’ Initial Access\n- Exploitation â†’ Execution\n- Installation â†’ Persistence\n- C2 â†’ Command and Control\n- Actions â†’ Collection, Exfiltration, Impact\n\n**Detection Coverage Analysis**\n\n*Process*\n1. Identify relevant threat actors\n2. Map their known TTPs (ATT&CK)\n3. Inventory current detections\n4. Map detections to techniques\n5. Identify gaps\n6. Prioritize development\n7. Validate detections\n\n*Coverage Visualization*\n- ATT&CK Navigator\n- Heat maps showing coverage\n- Gap identification\n- Progress tracking\n\n**Threat-Informed Defense**\n\n*Concept*\n- Base defenses on actual threats\n- Prioritize relevant techniques\n- Don't defend against everything equally\n- Focus on likely attack paths\n\n*Implementation*\n- Threat intelligence integration\n- Industry-specific threat analysis\n- Regular reassessment\n- Continuous improvement\n\n**Purple Teaming**\n\n*Definition*\n- Collaboration between red and blue teams\n- Attack simulation with defense tuning\n- Real-time feedback loop\n- Maximize learning\n\n*Benefits*\n- Immediate detection improvement\n- Validated defense effectiveness\n- Knowledge transfer\n- Efficient use of resources\n\n**Measuring Defensive Capability**\n\n*Metrics*\n- ATT&CK technique coverage percentage\n- Detection rate per technique\n- Time to detect by technique\n- False positive rate\n- Improvement over time\n\n*Maturity Assessment*\n- Can we detect this technique?\n- How quickly do we detect it?\n- Can we respond effectively?\n- Have we validated detection works?",

      "key_points": [
        "Combine frameworks: Kill Chain (flow), ATT&CK (techniques), Diamond (analysis)",
        "Map detections to ATT&CK techniques to identify coverage gaps",
        "Threat-informed defense prioritizes relevant threats over generic coverage",
        "Purple teaming combines red (attack) and blue (defense) for rapid improvement",
        "Measure detection coverage, detection rate, and time to detect"
      ],

      "real_world_example": {
        "scenario": "Purple team exercise improving detection",
        "company": "NexaTech Solutions",
        "application": "NexaTech ran a purple team exercise focusing on credential access: PLANNING (red team would attempt T1003 OS Credential Dumping, blue team would tune detection), EXECUTION (red team used Mimikatz variants; blue team monitored in real-time), ITERATION 1 (initial detection missed obfuscated Mimikatzâ€”blue team tuned SIEM rule), ITERATION 2 (detection triggered but with noiseâ€”adjusted threshold), ITERATION 3 (clean detection, automated alert to SOC), ITERATION 4 (tested Mimikatz alternativesâ€”confirmed detection of technique not just tool), OUTCOME (detection coverage for T1003 improved from 'none' to 'validated high-confidence'), DOCUMENTATION (updated playbook, detection rules, and training materials). Single 4-hour session dramatically improved one critical detection."
      },

      "exam_tips": [
        "Kill Chain stages map to ATT&CK tactics",
        "ATT&CK Navigator visualizes technique coverage",
        "Purple team = red + blue collaboration",
        "Threat-informed defense prioritizes relevant threats",
        "Measure coverage, detection rate, time to detect"
      ],

      "glossary_terms": [
        {
          "term": "Purple Team",
          "definition": "A collaborative security approach where red team (attackers) and blue team (defenders) work together to improve detection and response capabilities.",
          "exam_note": "Red + blue collaboration. Real-time improvement. Knowledge sharing. Efficient."
        },
        {
          "term": "Threat-Informed Defense",
          "definition": "A security approach that prioritizes defenses based on actual threat intelligence about adversaries likely to target the organization.",
          "exam_note": "Defense based on real threats. Prioritize relevant techniques. Not equal defense everywhere."
        },
        {
          "term": "ATT&CK Navigator",
          "definition": "A tool for visualizing ATT&CK technique coverage, enabling organizations to see defensive gaps and track improvements.",
          "exam_note": "Visualizes coverage. Shows gaps. Heat maps. Track improvement."
        },
        {
          "term": "Detection Coverage",
          "definition": "The percentage of adversary techniques for which an organization has working detection capabilities.",
          "exam_note": "What % of techniques can we detect? Map to ATT&CK. Identify gaps."
        }
      ],

      "knowledge_check": {
        "question": "An organization wants to validate their SIEM detection rules against real attack techniques. The red team executes Mimikatz while the blue team monitors and tunes detection rules in real-time. This collaborative approach is called:",
        "options": [
          "Penetration testing because the red team is attacking",
          "Vulnerability assessment because they're testing defenses",
          "Purple teaming because red and blue teams are collaborating",
          "Threat hunting because they're looking for attacks"
        ],
        "correct": 2,
        "explanation": "This is purple teamingâ€”the collaboration between red team (executing attacks) and blue team (tuning detection) in real-time to rapidly improve defensive capabilities. Penetration testing is typically separate from defense. Vulnerability assessment doesn't involve attack execution. Threat hunting searches for unknown threats."
      }
    }
  ],

  "hands_on_activity": {
    "title": "Attack Framework Analysis Exercise",
    "objective": "Apply multiple frameworks to analyze and respond to an attack scenario",
    "scenario": "You're analyzing an incident at Apex Consulting Group where attackers compromised systems and exfiltrated data.",
    "steps": [
      "Step 1: Review this attack timeline:\n   - Day 1: Employee received spear phishing email with malicious document\n   - Day 1: Document opened, macro executed PowerShell downloading payload\n   - Day 2: Malware beaconed to C2 server every 30 minutes\n   - Day 3: Attacker ran Mimikatz, captured domain admin credentials\n   - Day 4: Attacker moved laterally to file server via RDP\n   - Day 5: Attacker compressed and exfiltrated 50GB of files to cloud storage\n   - Day 7: SOC detected unusual cloud upload, initiated response",
      "Step 2: Map each event to the Cyber Kill Chain stage:\n   - Which stage was each activity?\n   - Where could the attack have been stopped?\n   - What defenses failed at each stage?",
      "Step 3: Map each event to MITRE ATT&CK:\n   - Identify the tactic for each activity\n   - Identify the specific technique (T number if you know it)\n   - What detections should have triggered?",
      "Step 4: Apply the Diamond Model:\n   - Adversary: What can you determine?\n   - Capability: What tools/techniques were used?\n   - Infrastructure: What attacker resources were involved?\n   - Victim: Who/what was targeted?",
      "Step 5: Develop detection improvements:\n   - For each ATT&CK technique identified\n   - What SIEM rule or detection would catch it?\n   - Prioritize by kill chain stage (earlier is better)",
      "Step 6: Design a purple team exercise to validate:\n   - Which detection gaps to test\n   - How red team would execute\n   - How blue team would validate",
      "Step 7: Write an executive summary using framework terminology"
    ],
    "expected_outcome": "Complete analysis including Kill Chain mapping, ATT&CK technique identification, Diamond Model analysis, detection improvements, and purple team exercise design.",
    "reflection_questions": [
      "At which kill chain stage would detection have prevented the most damage?",
      "How do the different frameworks provide complementary views of the attack?",
      "What would a threat-informed defense approach prioritize for this organization?"
    ]
  },

  "what_would_you_do": {
    "scenario": "You're the security manager at GlobalRetail. Your SIEM vendor provides out-of-the-box rules but you're not sure how effective they are. A colleague suggests just enabling all rules, while another suggests only enabling rules for threats in the news. You have limited SOC resources to handle alerts.",
    "context": "Your organization has never mapped detection coverage. SOC handles 200 alerts/day currently. Budget doesn't allow for new tools. Industry peers have been targeted by ransomware and supply chain attacks.",
    "question": "How do you approach improving your detection capability?",
    "options": [
      {
        "id": "a",
        "text": "Enable all vendor rules to maximize coverage",
        "is_best": false,
        "feedback": "Enabling all rules without assessment will likely overwhelm your SOC with alerts they can't investigate, leading to alert fatigue and missed real threats. More rules doesn't equal better detection if you can't act on the alerts.",
        "consequences": "Alert volume increases dramatically. SOC overwhelmed. Important alerts missed. No improvement in actual detection capability. May create false sense of security."
      },
      {
        "id": "b",
        "text": "Map current rules to ATT&CK, identify gaps against relevant threats, and prioritize improvements",
        "is_best": true,
        "feedback": "This threat-informed defense approach ensures you're detecting what matters. Map existing rules to ATT&CK, analyze threats targeting your industry (ransomware, supply chain), identify gaps in those specific techniques, and prioritize enabling/creating rules for the gaps. This maximizes effectiveness without overwhelming resources.",
        "consequences": "Understand current coverage. Identify meaningful gaps. Prioritize relevant threats. Efficient use of SOC resources. Measurable improvement."
      },
      {
        "id": "c",
        "text": "Only enable rules for threats that have been in recent news",
        "is_best": false,
        "feedback": "Reactive detection based on news is always behind. By the time something is in the news, you've already missed the attack window. You need proactive, threat-informed detection based on what's likely to target you, not just what's already happened.",
        "consequences": "Always reactive. Miss current attacks. Coverage gaps for non-newsworthy threats. No systematic improvement. May miss targeted attacks that don't make news."
      },
      {
        "id": "d",
        "text": "Hire a red team to find what's not detected",
        "is_best": false,
        "feedback": "Red teaming is valuable but expensive and point-in-time. Without first understanding your detection baseline and threat model, you won't know what to prioritize. Map your coverage first, then use red/purple teaming to validate specific gaps.",
        "consequences": "Expensive. Point-in-time snapshot. May test irrelevant techniques. No systematic improvement process. Better after baseline is established."
      }
    ],
    "key_lesson": "Effective detection requires a threat-informed approach. Use ATT&CK to understand what you're detecting, analyze threats relevant to your industry, and prioritize gaps in techniques those threats actually use. This focused approach is more effective than enabling everything (alert fatigue) or reacting to news (always behind). Map â†’ Analyze â†’ Prioritize â†’ Improve â†’ Validate."
  },

  "summary": {
    "key_takeaways": [
      "Cyber Kill Chain: 7 stages from Recon to Actions; break any stage to disrupt",
      "MITRE ATT&CK: Tactics (goals) + Techniques (methods); 14 Enterprise tactics",
      "Diamond Model: Adversary, Capability, Infrastructure, Victim; enables attribution",
      "PTES: 7-phase pen testing methodology; OWASP for web applications",
      "Purple teaming combines red and blue for rapid detection improvement",
      "Threat-informed defense prioritizes relevant threats over generic coverage"
    ],
    "exam_essentials": [
      "Kill Chain: Recon â†’ Weaponization â†’ Delivery â†’ Exploitation â†’ Installation â†’ C2 â†’ Actions",
      "ATT&CK: Tactics = what (goals); Techniques = how (methods); 14 Enterprise tactics",
      "Diamond Model: 4 vertices for intrusion analysis and attribution",
      "Double-blind = testers AND defenders uninformed (most realistic)",
      "Red team = adversary simulation (objectives); Pen test = vulnerability finding (coverage)",
      "Purple team = red + blue collaboration for detection improvement"
    ],
    "connection_to_next": "Attack frameworks help us understand how attacks work. The final lesson in Domain 2 brings together everything by exploring security assessmentsâ€”how organizations systematically evaluate their security posture using all the concepts we've covered."
  },

  "related_content": {
    "simulations": ["D2-SIM-001"],
    "remediation": ["D2-REM-001"],
    "next_lesson": "D2-LESSON-012",
    "previous_lesson": "D2-LESSON-010"
  }
}
